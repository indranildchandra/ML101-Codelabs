{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperasOnColabExample.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indranildchandra/ML101-Codelabs/blob/master/src/HyperasOnColabExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FYdi32_ixNJY",
        "colab_type": "code",
        "outputId": "ef48d9f1-6b83-4c03-d72b-9dbf72eed734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/54/72/5533b6bf9b47dc33685c3e62c391d6eab5785a648a5ffa841e240a3db3fe/hyperas-0.4.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.4.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (6.0.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (4.5.3)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/c2/e676da701cda11b32ff42eceb44aa7d8934b597d604bb5e94c0283def064/prompt_toolkit-2.0.8-py3-none-any.whl (342kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->hyperas) (1.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (40.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Building wheels for collected packages: hyperas\n",
            "  Building wheel for hyperas (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/38/3f/27826f57fae60ef788ceb47e2c649590ab8af31f42075325d2\n",
            "Successfully built hyperas\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: hyperas, prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "Successfully installed hyperas-0.4 prompt-toolkit-2.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.7.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3rEszUh5TuI",
        "colab_type": "code",
        "outputId": "2a1a274d-a99e-4a92-b46a-50130d3f628b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FdFjtmrj5Gfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data():\n",
        "    '''\n",
        "    Data providing function:\n",
        "    This function is separated from model() so that hyperopt\n",
        "    won't reload data for each evaluation run.\n",
        "    '''\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = X_train.reshape(60000, 784)\n",
        "    X_test = X_test.reshape(10000, 784)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "    nb_classes = 10\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIygRZ6f5UkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "    '''\n",
        "    Model providing function:\n",
        "    Create Keras model with double curly brackets dropped-in as needed.\n",
        "    Return value has to be a valid python dictionary with two customary keys:\n",
        "        - loss: Specify a numeric evaluation metric to be minimized\n",
        "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "    The last one is optional, though recommended, namely:\n",
        "        - model: specify the model just created so that we can later use it again.\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # If we choose 'four', add an additional fourth layer\n",
        "    if {{choice(['three', 'four'])}} == 'four':\n",
        "        model.add(Dense(100))\n",
        "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              nb_epoch=1,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjlatkWq5Wab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2577665d-ef52-4685-9241-b7ccca064c44"
      },
      "cell_type": "code",
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='HyperasOnColabExample.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('HyperasOnColabExample.ipynb')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 17.5MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 5.5MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 7.7MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 4.6MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 5.7MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 6.6MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 7.5MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 8.4MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 9.3MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 7.3MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 7.5MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 9.5MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 9.4MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 16.6MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 16.7MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 16.7MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 16.3MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 16.5MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 16.4MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 40.6MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 21.0MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 21.3MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 21.7MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 21.3MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 21.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 20.2MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 21.2MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 21.2MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 21.2MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 21.9MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 46.5MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 45.3MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 45.9MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 40.0MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 39.8MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 45.1MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 45.0MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 44.5MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 29.8MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 29.3MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 28.7MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 27.8MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 27.5MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 29.7MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 29.5MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 29.5MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 29.6MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 29.7MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 44.4MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 43.2MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 44.5MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 48.4MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 48.6MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 52.4MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 53.0MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 51.1MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 51.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 51.2MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 51.7MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 56.0MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 54.9MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 55.1MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 54.1MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 52.5MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 40.8MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 41.4MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 40.9MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 41.1MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 39.5MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 39.4MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 39.6MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 38.6MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 38.4MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 38.3MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 48.3MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 49.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 49.5MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 49.2MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 49.9MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 45.9MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 43.8MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 43.3MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 44.5MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 41.9MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 41.8MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 41.7MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 41.8MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 41.9MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 42.9MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 46.1MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 48.8MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 50.7MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 50.5MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 54.9MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 54.8MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 53.2MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 19.3MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rdo3mScvBHF4",
        "colab_type": "code",
        "outputId": "fa9c4731-ab46-473b-c601-e6397687cef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3043
        }
      },
      "cell_type": "code",
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          max_evals=10,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='HyperasOnColabExample', # This is important!\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
            "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: '''\n",
            "  3: Data providing function:\n",
            "  4: This function is separated from model() so that hyperopt\n",
            "  5: won't reload data for each evaluation run.\n",
            "  6: '''\n",
            "  7: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
            "  8: X_train = X_train.reshape(60000, 784)\n",
            "  9: X_test = X_test.reshape(10000, 784)\n",
            " 10: X_train = X_train.astype('float32')\n",
            " 11: X_test = X_test.astype('float32')\n",
            " 12: X_train /= 255\n",
            " 13: X_test /= 255\n",
            " 14: nb_classes = 10\n",
            " 15: Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            " 16: Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     '''\n",
            "   4:     Model providing function:\n",
            "   5:     Create Keras model with double curly brackets dropped-in as needed.\n",
            "   6:     Return value has to be a valid python dictionary with two customary keys:\n",
            "   7:         - loss: Specify a numeric evaluation metric to be minimized\n",
            "   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "   9:     The last one is optional, though recommended, namely:\n",
            "  10:         - model: specify the model just created so that we can later use it again.\n",
            "  11:     '''\n",
            "  12:     model = Sequential()\n",
            "  13:     model.add(Dense(512, input_shape=(784,)))\n",
            "  14:     model.add(Activation('relu'))\n",
            "  15:     model.add(Dropout(space['Dropout']))\n",
            "  16:     model.add(Dense(space['Dense']))\n",
            "  17:     model.add(Activation(space['Activation']))\n",
            "  18:     model.add(Dropout(space['Dropout_1']))\n",
            "  19: \n",
            "  20:     # If we choose 'four', add an additional fourth layer\n",
            "  21:     if space['Dropout_2'] == 'four':\n",
            "  22:         model.add(Dense(100))\n",
            "  23:         model.add(space['add'])\n",
            "  24:         model.add(Activation('relu'))\n",
            "  25: \n",
            "  26:     model.add(Dense(10))\n",
            "  27:     model.add(Activation('softmax'))\n",
            "  28: \n",
            "  29:     model.compile(loss='categorical_crossentropy',\n",
            "  30:                   optimizer=space['optimizer'],\n",
            "  31:                   metrics=['accuracy'])\n",
            "  32: \n",
            "  33:     model.fit(X_train, Y_train,\n",
            "  34:               batch_size=space['batch_size'],\n",
            "  35:               nb_epoch=1,\n",
            "  36:               verbose=2,\n",
            "  37:               validation_data=(X_test, Y_test))\n",
            "  38:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  39:     print('Test accuracy:', acc)\n",
            "  40:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  41: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:115: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 1.6897 - acc: 0.4358 - val_loss: 0.7897 - val_acc: 0.8182\n",
            "Test accuracy: 0.8182\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 2.1494 - acc: 0.3016 - val_loss: 0.6890 - val_acc: 0.8219\n",
            "Test accuracy: 0.8219\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 6s - loss: 1.9368 - acc: 0.3153 - val_loss: 0.6496 - val_acc: 0.8737\n",
            "Test accuracy: 0.8737\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 0.7218 - acc: 0.7695 - val_loss: 0.1958 - val_acc: 0.9396\n",
            "Test accuracy: 0.9396\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 0.5352 - acc: 0.8388 - val_loss: 0.1737 - val_acc: 0.9463\n",
            "Test accuracy: 0.9463\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 2.7076 - acc: 0.1101 - val_loss: 2.1694 - val_acc: 0.4614\n",
            "Test accuracy: 0.4614\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 3s - loss: 0.2765 - acc: 0.9152 - val_loss: 0.1218 - val_acc: 0.9620\n",
            "Test accuracy: 0.962\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 2.2134 - acc: 0.1962 - val_loss: 1.8998 - val_acc: 0.6052\n",
            "Test accuracy: 0.6052\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 0.4606 - acc: 0.8537 - val_loss: 0.1795 - val_acc: 0.9444\n",
            "Test accuracy: 0.9444\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 7s - loss: 0.2958 - acc: 0.9082 - val_loss: 0.1173 - val_acc: 0.9628\n",
            "Test accuracy: 0.9628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UaEviY3SbLlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}