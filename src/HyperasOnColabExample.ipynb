{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperasOnColabExample.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indranildchandra/ML101-Codelabs/blob/master/src/HyperasOnColabExample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FYdi32_ixNJY",
        "colab_type": "code",
        "outputId": "ef48d9f1-6b83-4c03-d72b-9dbf72eed734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1329
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/54/72/5533b6bf9b47dc33685c3e62c391d6eab5785a648a5ffa841e240a3db3fe/hyperas-0.4.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.2.4)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (4.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.4.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.0.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.7.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.4.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (6.0.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.4.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.6.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.10)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.1.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.5.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt->hyperas) (4.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.2.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (4.5.3)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->hyperas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/c2/e676da701cda11b32ff42eceb44aa7d8934b597d604bb5e94c0283def064/prompt_toolkit-2.0.8-py3-none-any.whl (342kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert->hyperas) (1.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas) (40.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->jupyter->hyperas) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->hyperas) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->hyperas) (0.1.7)\n",
            "Building wheels for collected packages: hyperas\n",
            "  Building wheel for hyperas (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/38/3f/27826f57fae60ef788ceb47e2c649590ab8af31f42075325d2\n",
            "Successfully built hyperas\n",
            "\u001b[31mipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: hyperas, prompt-toolkit\n",
            "  Found existing installation: prompt-toolkit 1.0.15\n",
            "    Uninstalling prompt-toolkit-1.0.15:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.15\n",
            "Successfully installed hyperas-0.4 prompt-toolkit-2.0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.11.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.7.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i3rEszUh5TuI",
        "colab_type": "code",
        "outputId": "2a1a274d-a99e-4a92-b46a-50130d3f628b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FdFjtmrj5Gfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data():\n",
        "    '''\n",
        "    Data providing function:\n",
        "    This function is separated from model() so that hyperopt\n",
        "    won't reload data for each evaluation run.\n",
        "    '''\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    X_train = X_train.reshape(60000, 784)\n",
        "    X_test = X_test.reshape(10000, 784)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train /= 255\n",
        "    X_test /= 255\n",
        "    nb_classes = 10\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIygRZ6f5UkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "    '''\n",
        "    Model providing function:\n",
        "    Create Keras model with double curly brackets dropped-in as needed.\n",
        "    Return value has to be a valid python dictionary with two customary keys:\n",
        "        - loss: Specify a numeric evaluation metric to be minimized\n",
        "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "    The last one is optional, though recommended, namely:\n",
        "        - model: specify the model just created so that we can later use it again.\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_shape=(784,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    # If we choose 'four', add an additional fourth layer\n",
        "    if {{choice(['three', 'four'])}} == 'four':\n",
        "        model.add(Dense(100))\n",
        "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
        "        model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Dense(10))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              epochs=1,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FjlatkWq5Wab",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='HyperasOnColabExample.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('HyperasOnColabExample.ipynb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdo3mScvBHF4",
        "colab_type": "code",
        "outputId": "63cca33e-5dfe-4f7b-81d2-b032bce90cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3043
        }
      },
      "cell_type": "code",
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          max_evals=10,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='HyperasOnColabExample', # This is important!\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.choice('Dropout_2', ['three', 'four']),\n",
            "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: '''\n",
            "  3: Data providing function:\n",
            "  4: This function is separated from model() so that hyperopt\n",
            "  5: won't reload data for each evaluation run.\n",
            "  6: '''\n",
            "  7: (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
            "  8: X_train = X_train.reshape(60000, 784)\n",
            "  9: X_test = X_test.reshape(10000, 784)\n",
            " 10: X_train = X_train.astype('float32')\n",
            " 11: X_test = X_test.astype('float32')\n",
            " 12: X_train /= 255\n",
            " 13: X_test /= 255\n",
            " 14: nb_classes = 10\n",
            " 15: Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            " 16: Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     '''\n",
            "   4:     Model providing function:\n",
            "   5:     Create Keras model with double curly brackets dropped-in as needed.\n",
            "   6:     Return value has to be a valid python dictionary with two customary keys:\n",
            "   7:         - loss: Specify a numeric evaluation metric to be minimized\n",
            "   8:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
            "   9:     The last one is optional, though recommended, namely:\n",
            "  10:         - model: specify the model just created so that we can later use it again.\n",
            "  11:     '''\n",
            "  12:     model = Sequential()\n",
            "  13:     model.add(Dense(512, input_shape=(784,)))\n",
            "  14:     model.add(Activation('relu'))\n",
            "  15:     model.add(Dropout(space['Dropout']))\n",
            "  16:     model.add(Dense(space['Dense']))\n",
            "  17:     model.add(Activation(space['Activation']))\n",
            "  18:     model.add(Dropout(space['Dropout_1']))\n",
            "  19: \n",
            "  20:     # If we choose 'four', add an additional fourth layer\n",
            "  21:     if space['Dropout_2'] == 'four':\n",
            "  22:         model.add(Dense(100))\n",
            "  23:         model.add(space['add'])\n",
            "  24:         model.add(Activation('relu'))\n",
            "  25: \n",
            "  26:     model.add(Dense(10))\n",
            "  27:     model.add(Activation('softmax'))\n",
            "  28: \n",
            "  29:     model.compile(loss='categorical_crossentropy',\n",
            "  30:                   optimizer=space['optimizer'],\n",
            "  31:                   metrics=['accuracy'])\n",
            "  32: \n",
            "  33:     model.fit(X_train, Y_train,\n",
            "  34:               batch_size=space['batch_size'],\n",
            "  35:               epochs=1,\n",
            "  36:               verbose=2,\n",
            "  37:               validation_data=(X_test, Y_test))\n",
            "  38:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  39:     print('Test accuracy:', acc)\n",
            "  40:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  41: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:115: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 1.6665 - acc: 0.4446 - val_loss: 0.7566 - val_acc: 0.8372\n",
            "Test accuracy: 0.8372\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 7s - loss: 2.1618 - acc: 0.2932 - val_loss: 0.7142 - val_acc: 0.8012\n",
            "Test accuracy: 0.8012\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 7s - loss: 1.9441 - acc: 0.3070 - val_loss: 0.6851 - val_acc: 0.8663\n",
            "Test accuracy: 0.8663\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.7161 - acc: 0.7704 - val_loss: 0.2080 - val_acc: 0.9380\n",
            "Test accuracy: 0.938\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.4938 - acc: 0.8502 - val_loss: 0.1635 - val_acc: 0.9476\n",
            "Test accuracy: 0.9476\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 4s - loss: 2.6887 - acc: 0.1119 - val_loss: 2.1659 - val_acc: 0.5288\n",
            "Test accuracy: 0.5288\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.2776 - acc: 0.9149 - val_loss: 0.1046 - val_acc: 0.9676\n",
            "Test accuracy: 0.9676\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 2.2287 - acc: 0.1846 - val_loss: 1.9452 - val_acc: 0.6175\n",
            "Test accuracy: 0.6175\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 5s - loss: 0.4546 - acc: 0.8541 - val_loss: 0.1812 - val_acc: 0.9428\n",
            "Test accuracy: 0.9428\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " - 9s - loss: 0.2969 - acc: 0.9075 - val_loss: 0.1338 - val_acc: 0.9598\n",
            "Test accuracy: 0.9598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UaEviY3SbLlB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}